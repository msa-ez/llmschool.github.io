{"hash":"96fb71c837f21a18e923352d77c459939a08c137","data":{"thisPage":{"id":"f3d7168080d3c0d2ee96cd83a9434c8c","name":"Ai-ops-trouble-shooting","mockData":"{\"AI Ops Trouble shooting\":\"Massachusetts\"}","source":"<template>\n    <div>\n        <mark-down class=\"content\" source='\n\n## OpenAI K8sGPT 활용\n\nCNCF에 등재된 K8sGPT OpenAI를 활용해 Kubernetes Cluster를 자동 진단하고 지속적인 운영을 위한 가이드로 내 클러스터의 문제점과 개선사항들을 자동으로 스캔하고 문제점을 해결할 수 있는 트러블 슈팅을 안내하겠습니다. \n\nCli 버전의 K8sGPT를 설치하여 원격에서 자동 탐지하는 방법과 K8s를 클러스터에 설치하여 운영하는 2가지 방식이 있으며 아래와 같이 진행할 수 있습니다.\n\n### K8sGPT Cli 설치\n\n- Homebrew를 활용한 Cli 설치\n```\nbrew tap k8sgpt-ai/k8sgpt\nbrew install k8sgpt\n```\n\n- 설치 확인\n```\nk8sgpt version\nk8sgpt --help\n```\n\n### Open AI Key 생성과 설정\n\nK8sGPT를 사용하기 위해 K8s gpt에 아래 명령으로 k8sgpt 에 접근한 후 OPEN AI API_Key를 입력합니다.\n```\nk8sgpt auth add openai\nEnter openai Key: \n\nopenai added to the AI backend provider list\n```\n- K8s gpt에는 기본 프로바이더외에 AzureOpenAI, Cohere, Amazon Bedrock, SageMaker 등 다양한 AI엔진을 백엔드를 설정해 프로바이더로 활용할 수 있습니다.\n- 설정값들은 ~/.config/k8sgpt/k8sgpt.yaml에 저장됩니다.\n\n- 등록된 Backends Provider 확인\n```\nk8sgpt auth list\n```\n\n### K8sGPT 사용하기\n\n먼저, 다음 (존재하지 않는) nginx 이미지로 YAML을 배포합니다.\n```\nkubectl apply -f - <<EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.14.100\n        ports:\n        - containerPort: 80\nEOF\n```\n- 클러스터를 분석하기 위해 다음의 명령어를 터미널에 입력합니다.\n```\nk8sgpt analyze\n```\n- 분석결과와 추천 솔루션을 포함하도록 요청합니다.\n```\nk8sgpt analyse --explain\n```\n- 출력 언어를 한글로 설정하여 확인할 수 있습니다.\n```\nk8sgpt analyse --explain --language \"Korean\"\n```\n- 설정을 추가하여 JSON 응답으로 Pretty하게 생성되기 위해 프롬프팅을 추가합니다.\n```\nk8sgpt analyze -o json --explain --filter=Pod -c --language \"Korean\" | jq .\n```\n- 출력된 결과는 다음과 같습니다.\n```json\n{\n  \"provider\": \"openai\",\n  \"errors\": null,\n  \"status\": \"ProblemDetected\",\n  \"problems\": 1,\n  \"results\": [\n    {\n      \"kind\": \"Pod\",\n      \"name\": \"default/nginx-deployment-744d99ff97-ngk6h\",\n      \"error\": [\n        {\n          \"Text\": \"Back-off pulling image \\\"nginx:1.14.100\\\"\",\n          \"KubernetesDoc\": \"\",\n          \"Sensitive\": []\n        }\n      ],\n      \"details\": \"Error: 이미지 \\\"nginx:1.14.100\\\" 가져오기를 다시 시도합니다.\\nSolution: \\n1. 도커 허브에서 nginx:1.14.100 이미지가 있는지 확인합니다.\\n2. 도커 허브에 문제가 있다면, 다른 도커 레지스트리에서 이미지를 가져옵니다.\\n3. 이미지 를 가져올 수 없는 경우, 이미지 이름 또는 태그를 확인하고 올바른 이미지를 사용합니다.\\n4. 네트워크 연결을 확인하고 필요한 경우 다시 시도합니다.\",\n      \"parentObject\": \"Deployment/nginx-deployment\"\n    }\n  ]\n}\n```\n\n### K8sGPT 확장\n\nK8sGPT는 Grafana, Prometheus와 같은 모니터링 도구와 쉽게 통합되며, K8sGPT용 플러그인을 생성해 연동하는 것이 가능합니다. 현재 지원하고 있는 플러그인 중, 클라우드 네이티브 Security Scanner인 Trivy를 다음과 같이 적용할 수 있습니다.\n\n```\nk8sgpt integration list\n```\n\n- Trivy Security Scanner를 다음과 같이 적용하여 취약점 분석에 사용할 수 있습니다.\n```\nk8sgpt integration activate trivy\nk8sgpt analyze --filter=VulnerabilityReport --explain\n```\n- 클러스터 보안취약점 분석 결과 예시\n![image](https://github.com/acmexii/demo/assets/35618409/9e328b9e-3d7c-4b84-bded-26d01a251272)\n\n\n### K8sGPT Operator 설치\n\nk8sgpt를 쿠버네티스 클러스터에 설치하여 주기적으로 배포된 객체들을 진단하고, 그 결과를 프로메테우스와 Grafana로 집계하고 시각화하여 운영하는 방법은 다음과 같습니다.\n\n- 먼저 k8sgpt Helm 리파지토리를 다음의 명령어로 실행합니다.\n```\nhelm repo add k8sgpt https://charts.k8sgpt.ai/\nhelm repo update\n```\n\n- 진단 결과 모니터링을 위해 Prometheus와 Grafana 서비스와의 연결을 활성화 시킵니다.\n```\nhelm show values k8sgpt/k8sgpt-operator > values.yml\nvi values.yml\n\n# 아래처럼 serviceMonitor, GrafanaDashboard를 활성화 시키고 values.yml을 저장합니다.\nserviceMonitor:\n  enabled: true\n\nGrafanaDashboard:\n  enabled: true\n```\n\n- K8sGPT Operator를 수정한 설정정보를 가진 values.yml로 설치하기 위해 다음의 명렁어를 입력합니다.\n```\nhelm install release k8sgpt/k8sgpt-operator -n k8sgpt-operator-system --create-namespace --values values.yml\n```\n\n- K8sGPT가 사용할 kube-prometheus-stack으로 Prometheus와 Grafana를 설치합니다.\n```\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo update\nhelm install prom prometheus-community/kube-prometheus-stack -n k8sgpt-operator-system --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false\n```\n\n- OpenAI Key Secret 객체를 생성합니다.\n```\nexport OPENAI_TOKEN=<YOUR API KEY HERE>\nkubectl create secret generic k8sgpt-sample-secret --from-literal=openai-api-key=$OPENAI_TOKEN -n k8sgpt-operator-system\n```\n\n- K8sGPT Operator가 사용할 GPT 버전과 백엔드 프로바이더를 다음과 같이 설정합니다.\n```\nkubectl apply -f - << EOF\napiVersion: core.k8sgpt.ai/v1alpha1\nkind: K8sGPT\nmetadata:\n  name: k8sgpt-sample\n  namespace: k8sgpt-operator-system\nspec:\n  ai:\n    enabled: true\n    model: gpt-3.5-turbo\n    backend: openai\n    secret:\n      name: k8sgpt-sample-secret\n      key: openai-api-key\n    # anonymized: false\n    # language: english\n  noCache: false\n  repository: ghcr.io/k8sgpt-ai/k8sgpt\n  version: v0.3.24      # k8sgpt version으로 조회된 값 입력\nEOF\n```\n\n### K8sGPT Operator 진단결과 확인\n\n#### Operator 설치 후, 아래 명령어로 결과를 조회할 수 있습니다.\n```\nkubectl get results -n k8sgpt-operator-system\n```\n\n#### Grafana를 통한 진단결과 시각화\n\n- 실행 중인, Grafana로 접속합니다.\n```\nkubectl port-forward service/prom-grafana -n k8sgpt-operator-system 3000:80\n```\n> 아이디: admin, 비번: prom-operator\n> 접속정보 확인: kubectl get secrets --namespace=k8sgpt-operator-system prom-grafana -ojsonpath=\"{.data.admin-user}\" | base64 -d\n\n#### Dashboards > K8sGPT Overview 메뉴를 통해 결과를 확인할 수 있습니다.\n![image](https://github.com/acmexii/demo/assets/35618409/d0da9ca9-d341-41b4-b6aa-4e87f7630208)\n'></mark-down>\n\n    </div>\n</template>\n\n\n<script>\n    // @group 01_04_04\n    export default {\n        name:'Ai-ops-trouble-shooting',\n        data() {\n            return {}\n        },\n        props: {\n            \"AI Ops Trouble shooting\": {\n                type: String\n            },\n        },\n    }\n</script>","path":"/operation/operate/ai-ops-trouble-shooting/","props":[{"name":"AI Ops Trouble shooting"}],"componentDesc":{"group":["01_04_04"]},"fileInfo":{"name":"Ai-ops-trouble-shooting","path":"operation/operate/Ai-ops-trouble-shooting.vue","directory":"operation/operate"}},"allPagesByName":{"edges":[{"node":{"id":"491a019883e24d1ade45318efd39fa7e","name":"index","path":"/operation/course/","props":[{"name":"교육과정 소개"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/course/index.vue","directory":"operation/course"}}},{"node":{"id":"ddac7512ff1cb42577161679388846a0","name":"index","path":"/operation/implement/","props":[{"name":"구현"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/implement/index.vue","directory":"operation/implement"}}},{"node":{"id":"f0100491817a80d842db3752e7a6c4f6","name":"index","path":"/operation/llm/","props":[{"name":"설치형 LLM"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/llm/index.vue","directory":"operation/llm"}}},{"node":{"id":"455485b89fc07a2011135c71b3e5b06d","name":"index","path":"/operation/introduction/","props":[{"name":"AI Tools"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/introduction/index.vue","directory":"operation/introduction"}}},{"node":{"id":"dfe15286a0af9af4cf957c89714797f4","name":"index","path":"/operation/llm-msaez/","props":[{"name":"설치형 LLM 기반 MSAEZ 연동"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/llm-msaez/index.vue","directory":"operation/llm-msaez"}}},{"node":{"id":"eeaab9630dc4711635747aa9fda862d7","name":"index","path":"/operation/planning/","props":[{"name":"분석/설계"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/planning/index.vue","directory":"operation/planning"}}},{"node":{"id":"0bb6a8c5fa0e1266e2ccecc243fa5470","name":"index","path":"/operation/operate/","props":[{"name":"배포/운영"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/operate/index.vue","directory":"operation/operate"}}},{"node":{"id":"ca5edeb926047bc16e52379ccb4cdbd6","name":"IDE","path":"/operation/introduction/ide/","props":[{"name":"Cursor IDE"}],"componentDesc":{"group":["01_01_02"]},"fileInfo":{"name":"IDE","path":"operation/introduction/IDE.vue","directory":"operation/introduction"}}},{"node":{"id":"b226ba8089a5b8e4cc79a46bdf60d587","name":"SW","path":"/operation/introduction/sw/","props":[{"name":"Cursor IDE- 테스트/ 디자인 패턴"}],"componentDesc":{"group":["01_01_03"]},"fileInfo":{"name":"SW","path":"operation/introduction/SW.vue","directory":"operation/introduction"}}},{"node":{"id":"ef65af528625f3df4341f189681a2066","name":"Legacy","path":"/operation/introduction/legacy/","props":[{"name":"Cursor IDE- 레거시 분석/ 전환"}],"componentDesc":{"group":["01_01_04"]},"fileInfo":{"name":"Legacy","path":"operation/introduction/Legacy.vue","directory":"operation/introduction"}}},{"node":{"id":"d894f03fb84bd2357e5f6115f61b2cd9","name":"GPT-Engineer","path":"/operation/introduction/gpt-engineer/","props":[{"name":"GPT-Engineer"}],"componentDesc":{"group":["01_01_05"]},"fileInfo":{"name":"Gpt-engineer","path":"operation/introduction/Gpt-engineer.vue","directory":"operation/introduction"}}},{"node":{"id":"7e9f91dcd66fc903b29ed35c1bdb3953","name":"Continue","path":"/operation/introduction/continue/","props":[{"name":"Continue"}],"componentDesc":{"group":["01_01_06"]},"fileInfo":{"name":"Continue","path":"operation/introduction/Continue.vue","directory":"operation/introduction"}}},{"node":{"id":"8436578d14e4c980d7c1ee8fa899962a","name":"Kubernetes","path":"/operation/introduction/kubectl-ai/","props":[{"name":"Kubectl-ai / K8sGPT"}],"componentDesc":{"group":["01_01_07"]},"fileInfo":{"name":"Kubectl-AI","path":"operation/introduction/Kubectl-AI.vue","directory":"operation/introduction"}}},{"node":{"id":"3bd2f88491ffe8e5d3e0cb8f5ad49c5e","name":"GPT-Engineer-dev","path":"/operation/implement/gpt-engineer-dev/","props":[{"name":"GPT-Engineer를 활용한 MSA 구현"}],"componentDesc":{"group":["01_03_02"]},"fileInfo":{"name":"GPT-Engineer-dev","path":"operation/implement/GPT-Engineer-dev.vue","directory":"operation/implement"}}},{"node":{"id":"bec8e6134b4833a31df0a230c20b0464","name":"Copilot-dev","path":"/operation/implement/copilot-dev/","props":[{"name":"Copilot을 활용한 비즈니스 로직 구현"}],"componentDesc":{"group":["01_03_03"]},"fileInfo":{"name":"Copilot-dev","path":"operation/implement/Copilot-dev.vue","directory":"operation/implement"}}},{"node":{"id":"c6aafe599a891c74b0fb229795490cdd","name":"Fastfood","path":"/operation/operate/copilot-dockerising/","props":[{"name":"Copilot을 활용한 클라우드 배포 준비"}],"componentDesc":{"group":["01_04_02"]},"fileInfo":{"name":"Copilot-dockerising","path":"operation/operate/Copilot-dockerising.vue","directory":"operation/operate"}}},{"node":{"id":"ac0be07f9c57dce30509a7d323a406e6","name":"Kubectl-ai","path":"/operation/operate/kubectl-ai/","props":[{"name":"AI기반 YAML 자동생성&오케스트레이션"}],"componentDesc":{"group":["01_04_03"]},"fileInfo":{"name":"Kubectl-ai","path":"operation/operate/Kubectl-ai.vue","directory":"operation/operate"}}},{"node":{"id":"f3d7168080d3c0d2ee96cd83a9434c8c","name":"Ai-ops-trouble-shooting","path":"/operation/operate/ai-ops-trouble-shooting/","props":[{"name":"AI Ops Trouble shooting"}],"componentDesc":{"group":["01_04_04"]},"fileInfo":{"name":"Ai-ops-trouble-shooting","path":"operation/operate/Ai-ops-trouble-shooting.vue","directory":"operation/operate"}}},{"node":{"id":"8de86484c2e4943142d33cb5568bad99","name":"AutoModeling","path":"/operation/planning/ai-auto-modeling/","props":[{"name":"AI를 활용한 MSA설계"}],"componentDesc":{"group":["02_01_02"]},"fileInfo":{"name":"Ai-auto-modeling","path":"operation/planning/Ai-auto-modeling.vue","directory":"operation/planning"}}},{"node":{"id":"67fce1267a39c0a7bb0c5dd6c672bf5c","name":"LLM-Model","path":"/operation/llm/llm-model/","props":[{"name":"Open source LLM"}],"componentDesc":{"group":["05_01_02"]},"fileInfo":{"name":"LLM-model","path":"operation/llm/LLM-model.vue","directory":"operation/llm"}}},{"node":{"id":"9c1074d7fbbfa5a2fe4bb5f110a69a37","name":"LLM-Setting","path":"/operation/llm/llm-setting/","props":[{"name":"설치형 LLM 기반 개발 환경 구성"}],"componentDesc":{"group":["05_01_03"]},"fileInfo":{"name":"LLM-setting","path":"operation/llm/LLM-setting.vue","directory":"operation/llm"}}},{"node":{"id":"54af858485f4cecbf0bea2b4c50dd6ca","name":"Ollama","path":"/operation/llm/ollama/","props":[{"name":"Ollama"}],"componentDesc":{"group":["05_01_04"]},"fileInfo":{"name":"ollama","path":"operation/llm/ollama.vue","directory":"operation/llm"}}},{"node":{"id":"0e989c2b68ff917575cb42a2c11b2b59","name":"Open-Web","path":"/operation/llm/open-web-ui/","props":[{"name":"Open Web UI"}],"componentDesc":{"group":["05_01_05"]},"fileInfo":{"name":"open-web-ui","path":"operation/llm/open-web-ui.vue","directory":"operation/llm"}}}]},"allPages":{"edges":[{"node":{"name":"Kubernetes","path":"/operation/introduction/kubectl-ai/","fileInfo":{"name":"Kubectl-AI","directory":"operation/introduction"}}},{"node":{"name":"Legacy","path":"/operation/introduction/legacy/","fileInfo":{"name":"Legacy","directory":"operation/introduction"}}},{"node":{"name":"Continue","path":"/operation/introduction/continue/","fileInfo":{"name":"Continue","directory":"operation/introduction"}}},{"node":{"name":"index","path":"/operation/operate/","fileInfo":{"name":"index","directory":"operation/operate"}}},{"node":{"name":"Kubectl-ai","path":"/operation/operate/kubectl-ai/","fileInfo":{"name":"Kubectl-ai","directory":"operation/operate"}}},{"node":{"name":"Fastfood","path":"/operation/operate/copilot-dockerising/","fileInfo":{"name":"Copilot-dockerising","directory":"operation/operate"}}},{"node":{"name":"AutoModeling","path":"/operation/planning/ai-auto-modeling/","fileInfo":{"name":"Ai-auto-modeling","directory":"operation/planning"}}},{"node":{"name":"Ai-ops-trouble-shooting","path":"/operation/operate/ai-ops-trouble-shooting/","fileInfo":{"name":"Ai-ops-trouble-shooting","directory":"operation/operate"}}},{"node":{"name":"index","path":"/operation/planning/","fileInfo":{"name":"index","directory":"operation/planning"}}},{"node":{"name":"index","path":"/operation/llm-msaez/","fileInfo":{"name":"index","directory":"operation/llm-msaez"}}},{"node":{"name":"SW","path":"/operation/introduction/sw/","fileInfo":{"name":"SW","directory":"operation/introduction"}}},{"node":{"name":"index","path":"/operation/introduction/","fileInfo":{"name":"index","directory":"operation/introduction"}}},{"node":{"name":"IDE","path":"/operation/introduction/ide/","fileInfo":{"name":"IDE","directory":"operation/introduction"}}},{"node":{"name":"GPT-Engineer","path":"/operation/introduction/gpt-engineer/","fileInfo":{"name":"Gpt-engineer","directory":"operation/introduction"}}},{"node":{"name":"Open-Web","path":"/operation/llm/open-web-ui/","fileInfo":{"name":"open-web-ui","directory":"operation/llm"}}},{"node":{"name":"Ollama","path":"/operation/llm/ollama/","fileInfo":{"name":"ollama","directory":"operation/llm"}}},{"node":{"name":"index","path":"/operation/llm/","fileInfo":{"name":"index","directory":"operation/llm"}}},{"node":{"name":"LLM-Model","path":"/operation/llm/llm-model/","fileInfo":{"name":"LLM-model","directory":"operation/llm"}}},{"node":{"name":"LLM-Setting","path":"/operation/llm/llm-setting/","fileInfo":{"name":"LLM-setting","directory":"operation/llm"}}},{"node":{"name":"GPT-Engineer-dev","path":"/operation/implement/gpt-engineer-dev/","fileInfo":{"name":"GPT-Engineer-dev","directory":"operation/implement"}}},{"node":{"name":"index","path":"/operation/implement/","fileInfo":{"name":"index","directory":"operation/implement"}}},{"node":{"name":"Copilot-dev","path":"/operation/implement/copilot-dev/","fileInfo":{"name":"Copilot-dev","directory":"operation/implement"}}},{"node":{"name":"index","path":"/operation/course/","fileInfo":{"name":"index","directory":"operation/course"}}}]}},"context":{"pathRegexp":"^$path.+$"}}