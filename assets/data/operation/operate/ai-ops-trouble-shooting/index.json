{"hash":"00f85a3c0db69bc8c92602c396639390e5359163","data":{"thisPage":{"id":"1bc6e9edd49039c5b6582aff860d11fd","name":"Ai-ops-trouble-shooting","mockData":"{\"Kubernetes Trouble shooting\":\"Small Plastic Computer\"}","source":"<template>\r\n    <div>\r\n        <mark-down class=\"content\" source='\r\n\r\n## K8sGPT를 활용한 k8s 트러블 슈팅\r\n\r\nCNCF에 등재된 K8sGPT OpenAI를 활용해 Kubernetes Cluster를 자동 진단하고 지속적인 운영을 위한 가이드로 내 클러스터의 문제점과 개선사항들을 자동으로 스캔하고 문제점을 해결할 수 있는 트러블 슈팅을 안내하겠습니다. \r\n\r\nCli 버전의 K8sGPT를 설치하여 원격에서 자동 탐지하는 방법과 K8s를 클러스터에 설치하여 운영하는 2가지 방식이 있으며 아래와 같이 진행할 수 있습니다.\r\n\r\n### K8sGPT Cli 설치\r\n\r\n- Homebrew를 활용한 Cli 설치\r\n```\r\nbrew tap k8sgpt-ai/k8sgpt\r\nbrew install k8sgpt\r\n```\r\n\r\n- 설치 확인\r\n```\r\nk8sgpt version\r\nk8sgpt --help\r\n```\r\n\r\n### Open AI Key 생성과 설정\r\n\r\nK8sGPT를 사용하기 위해 K8s gpt에 아래 명령으로 k8sgpt 에 접근한 후 OPEN AI API_Key를 입력합니다.\r\n```\r\nk8sgpt auth add openai\r\nEnter openai Key: \r\n\r\nopenai added to the AI backend provider list\r\n```\r\n- K8s gpt에는 기본 프로바이더외에 AzureOpenAI, Cohere, Amazon Bedrock, SageMaker 등 다양한 AI엔진을 백엔드를 설정해 프로바이더로 활용할 수 있습니다.\r\n- 설정값들은 ~/.config/k8sgpt/k8sgpt.yaml에 저장됩니다.\r\n\r\n- 등록된 Backends Provider 확인\r\n```\r\nk8sgpt auth list\r\n```\r\n\r\n### K8sGPT 사용하기\r\n\r\n먼저, 다음 (존재하지 않는) nginx 이미지로 YAML을 배포합니다.\r\n```\r\nkubectl apply -f - <<EOF\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: nginx-deployment\r\n  labels:\r\n    app: nginx\r\nspec:\r\n  replicas: 3\r\n  selector:\r\n    matchLabels:\r\n      app: nginx\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: nginx\r\n    spec:\r\n      containers:\r\n      - name: nginx\r\n        image: nginx:1.14.100\r\n        ports:\r\n        - containerPort: 80\r\nEOF\r\n```\r\n- 클러스터를 분석하기 위해 다음의 명령어를 터미널에 입력합니다.\r\n```\r\nk8sgpt analyze\r\n```\r\n- 분석결과와 추천 솔루션을 포함하도록 요청합니다.\r\n```\r\nk8sgpt analyse --explain\r\n```\r\n- 출력 언어를 한글로 설정하여 확인할 수 있습니다.\r\n```\r\nk8sgpt analyse --explain --language \"Korean\"\r\n```\r\n- 설정을 추가하여 JSON 응답으로 Pretty하게 생성되기 위해 프롬프팅을 추가합니다.\r\n```\r\nk8sgpt analyze -o json --explain --filter=Pod -c --language \"Korean\" | jq .\r\n```\r\n- 출력된 결과는 다음과 같습니다.\r\n```json\r\n{\r\n  \"provider\": \"openai\",\r\n  \"errors\": null,\r\n  \"status\": \"ProblemDetected\",\r\n  \"problems\": 1,\r\n  \"results\": [\r\n    {\r\n      \"kind\": \"Pod\",\r\n      \"name\": \"default/nginx-deployment-744d99ff97-ngk6h\",\r\n      \"error\": [\r\n        {\r\n          \"Text\": \"Back-off pulling image \\\"nginx:1.14.100\\\"\",\r\n          \"KubernetesDoc\": \"\",\r\n          \"Sensitive\": []\r\n        }\r\n      ],\r\n      \"details\": \"Error: 이미지 \\\"nginx:1.14.100\\\" 가져오기를 다시 시도합니다.\\nSolution: \\n1. 도커 허브에서 nginx:1.14.100 이미지가 있는지 확인합니다.\\n2. 도커 허브에 문제가 있다면, 다른 도커 레지스트리에서 이미지를 가져옵니다.\\n3. 이미지 를 가져올 수 없는 경우, 이미지 이름 또는 태그를 확인하고 올바른 이미지를 사용합니다.\\n4. 네트워크 연결을 확인하고 필요한 경우 다시 시도합니다.\",\r\n      \"parentObject\": \"Deployment/nginx-deployment\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n### K8sGPT 확장\r\n\r\nK8sGPT는 Grafana, Prometheus와 같은 모니터링 도구와 쉽게 통합되며, K8sGPT용 플러그인을 생성해 연동하는 것이 가능합니다. 현재 지원하고 있는 플러그인 중, 클라우드 네이티브 Security Scanner인 Trivy를 다음과 같이 적용할 수 있습니다.\r\n\r\n```\r\nk8sgpt integration list\r\n```\r\n\r\n- Trivy Security Scanner를 다음과 같이 적용하여 취약점 분석에 사용할 수 있습니다.\r\n```\r\nk8sgpt integration activate trivy\r\nk8sgpt analyze --filter=VulnerabilityReport --explain\r\n```\r\n- 클러스터 보안취약점 분석 결과 예시\r\n![image](https://github.com/acmexii/demo/assets/35618409/9e328b9e-3d7c-4b84-bded-26d01a251272)\r\n\r\n\r\n### K8sGPT Operator 설치\r\n\r\nk8sgpt를 쿠버네티스 클러스터에 설치하여 주기적으로 배포된 객체들을 진단하고, 그 결과를 프로메테우스와 Grafana로 집계하고 시각화하여 운영하는 방법은 다음과 같습니다.\r\n\r\n- 먼저 k8sgpt Helm 리파지토리를 다음의 명령어로 실행합니다.\r\n```\r\nhelm repo add k8sgpt https://charts.k8sgpt.ai/\r\nhelm repo update\r\n```\r\n\r\n- 진단 결과 모니터링을 위해 Prometheus와 Grafana 서비스와의 연결을 활성화 시킵니다.\r\n```\r\nhelm show values k8sgpt/k8sgpt-operator > values.yml\r\nvi values.yml\r\n\r\n# 아래처럼 serviceMonitor, GrafanaDashboard를 활성화 시키고 values.yml을 저장합니다.\r\nserviceMonitor:\r\n  enabled: true\r\n\r\nGrafanaDashboard:\r\n  enabled: true\r\n```\r\n\r\n- K8sGPT Operator를 수정한 설정정보를 가진 values.yml로 설치하기 위해 다음의 명렁어를 입력합니다.\r\n```\r\nhelm install release k8sgpt/k8sgpt-operator -n k8sgpt-operator-system --create-namespace --values values.yml\r\n```\r\n\r\n- K8sGPT가 사용할 kube-prometheus-stack으로 Prometheus와 Grafana를 설치합니다.\r\n```\r\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\r\nhelm repo update\r\nhelm install prom prometheus-community/kube-prometheus-stack -n k8sgpt-operator-system --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false\r\n```\r\n\r\n- OpenAI Key Secret 객체를 생성합니다.\r\n```\r\nexport OPENAI_TOKEN=<YOUR API KEY HERE>\r\nkubectl create secret generic k8sgpt-sample-secret --from-literal=openai-api-key=$OPENAI_TOKEN -n k8sgpt-operator-system\r\n```\r\n\r\n- K8sGPT Operator가 사용할 GPT 버전과 백엔드 프로바이더를 다음과 같이 설정합니다.\r\n```\r\nkubectl apply -f - << EOF\r\napiVersion: core.k8sgpt.ai/v1alpha1\r\nkind: K8sGPT\r\nmetadata:\r\n  name: k8sgpt-sample\r\n  namespace: k8sgpt-operator-system\r\nspec:\r\n  ai:\r\n    enabled: true\r\n    model: gpt-3.5-turbo\r\n    backend: openai\r\n    secret:\r\n      name: k8sgpt-sample-secret\r\n      key: openai-api-key\r\n    # anonymized: false\r\n    # language: english\r\n  noCache: false\r\n  repository: ghcr.io/k8sgpt-ai/k8sgpt\r\n  version: v0.3.24      # k8sgpt version으로 조회된 값 입력\r\nEOF\r\n```\r\n\r\n### K8sGPT Operator 진단결과 확인\r\n\r\n#### Operator 설치 후, 아래 명령어로 결과를 조회할 수 있습니다.\r\n```\r\nkubectl get results -n k8sgpt-operator-system\r\n```\r\n\r\n#### Grafana를 통한 진단결과 시각화\r\n\r\n- 실행 중인, Grafana로 접속합니다.\r\n```\r\nkubectl port-forward service/prom-grafana -n k8sgpt-operator-system 3000:80\r\n```\r\n> 아이디: admin, 비번: prom-operator\r\n> 접속정보 확인: kubectl get secrets --namespace=k8sgpt-operator-system prom-grafana -ojsonpath=\"{.data.admin-user}\" | base64 -d\r\n\r\n#### Dashboards > K8sGPT Overview 메뉴를 통해 결과를 확인할 수 있습니다.\r\n![image](https://github.com/acmexii/demo/assets/35618409/d0da9ca9-d341-41b4-b6aa-4e87f7630208)\r\n'></mark-down>\r\n\r\n    </div>\r\n</template>\r\n\r\n\r\n<script>\r\n    // @group 01_04_04\r\n    export default {\r\n        name:'Ai-ops-trouble-shooting',\r\n        data() {\r\n            return {}\r\n        },\r\n        props: {\r\n            \"Kubernetes Trouble shooting\": {\r\n                type: String\r\n            },\r\n        },\r\n    }\r\n</script>","path":"/operation/operate/ai-ops-trouble-shooting/","props":[{"name":"Kubernetes Trouble shooting"}],"componentDesc":{"group":["01_04_04"]},"fileInfo":{"name":"Ai-ops-trouble-shooting","path":"operation/operate/Ai-ops-trouble-shooting.vue","directory":"operation/operate"}},"allPagesByName":{"edges":[{"node":{"id":"42a785c750fee77c12bd370a33da8092","name":"index","path":"/llm/llm/","props":[{"name":"설치형 LLM"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"llm/llm/index.vue","directory":"llm/llm"}}},{"node":{"id":"296398f382963f74036f9b5dcc745e91","name":"index","path":"/operation/course/","props":[{"name":"교육과정 소개"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/course/index.vue","directory":"operation/course"}}},{"node":{"id":"5d90dd3369652db074abbfe45c92a79c","name":"index","path":"/operation/implement/","props":[{"name":"구현"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/implement/index.vue","directory":"operation/implement"}}},{"node":{"id":"be7d06ff70ab0f0462f29187d8d8114b","name":"index","path":"/operation/llm-msaez/","props":[{"name":"Overview"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/llm-msaez/index.vue","directory":"operation/llm-msaez"}}},{"node":{"id":"98ae4b6ad6456be10dc0ab3c6ff225cc","name":"index","path":"/operation/planning/","props":[{"name":"분석/설계"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/planning/index.vue","directory":"operation/planning"}}},{"node":{"id":"986c6ca74c7baaaf54586af6a3448b62","name":"index","path":"/operation/introduction/","props":[{"name":"AI 코딩 도구"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/introduction/index.vue","directory":"operation/introduction"}}},{"node":{"id":"8a68cd853c37a94b079386a11b37aa99","name":"index","path":"/operation/operate/","props":[{"name":"배포/운영"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/operate/index.vue","directory":"operation/operate"}}},{"node":{"id":"c11b5e3dc39abb5b06d5e9b7b27aa48a","name":"IDE","path":"/operation/introduction/ide/","props":[{"name":"Cursor IDE"}],"componentDesc":{"group":["01_01_02"]},"fileInfo":{"name":"IDE","path":"operation/introduction/IDE.vue","directory":"operation/introduction"}}},{"node":{"id":"81e96c049536a8c886ef18cecb45cd81","name":"SW","path":"/operation/introduction/sw/","props":[{"name":"┗ 테스트생성과 리팩토링"}],"componentDesc":{"group":["01_01_03"]},"fileInfo":{"name":"SW","path":"operation/introduction/SW.vue","directory":"operation/introduction"}}},{"node":{"id":"253266c5ed8852c96bc2dc2f599df41c","name":"Legacy","path":"/operation/introduction/legacy/","props":[{"name":"┗ 레거시분석과 모더나이징"}],"componentDesc":{"group":["01_01_04"]},"fileInfo":{"name":"Legacy","path":"operation/introduction/Legacy.vue","directory":"operation/introduction"}}},{"node":{"id":"8e7686d22cea4cd36416b65951e5fd53","name":"GPT-Engineer","path":"/operation/introduction/gpt-engineer/","props":[{"name":"GPT-Engineer"}],"componentDesc":{"group":["01_01_05"]},"fileInfo":{"name":"Gpt-engineer","path":"operation/introduction/Gpt-engineer.vue","directory":"operation/introduction"}}},{"node":{"id":"77072554ab3777a8fb3b06f9fcbdd775","name":"Continue","path":"/operation/introduction/continue/","props":[{"name":"Continue 코파일럿"}],"componentDesc":{"group":["01_01_06"]},"fileInfo":{"name":"Continue","path":"operation/introduction/Continue.vue","directory":"operation/introduction"}}},{"node":{"id":"64f93e5b45b1005f807e2c09495949fe","name":"Kubernetes","path":"/operation/introduction/kubectl-ai/","props":[{"name":"쿠버네티스 AI 플러그인"}],"componentDesc":{"group":["01_01_07"]},"fileInfo":{"name":"Kubectl-AI","path":"operation/introduction/Kubectl-AI.vue","directory":"operation/introduction"}}},{"node":{"id":"1c8e15a562e81e7c608fc5c04e215c69","name":"GPT-Engineer-dev","path":"/operation/implement/gpt-engineer-dev/","props":[{"name":"MSA Chassis by Autopilot"}],"componentDesc":{"group":["01_03_02"]},"fileInfo":{"name":"GPT-Engineer-dev","path":"operation/implement/GPT-Engineer-dev.vue","directory":"operation/implement"}}},{"node":{"id":"45bb74a431bc74bebf8b1ee32eef9e8b","name":"Copilot-dev","path":"/operation/implement/copilot-dev/","props":[{"name":"Business Logic by Copilot"}],"componentDesc":{"group":["01_03_03"]},"fileInfo":{"name":"Copilot-dev","path":"operation/implement/Copilot-dev.vue","directory":"operation/implement"}}},{"node":{"id":"7b93fc4038b827dada41c4dfc9a03c47","name":"Fastfood","path":"/operation/operate/copilot-dockerising/","props":[{"name":"Github Action 활용"}],"componentDesc":{"group":["01_04_02"]},"fileInfo":{"name":"Copilot-dockerising","path":"operation/operate/Copilot-dockerising.vue","directory":"operation/operate"}}},{"node":{"id":"4397e8ca21f973309ca5c47400bb62f6","name":"Kubectl-ai","path":"/operation/operate/kubectl-ai/","props":[{"name":"Kubectl OpenAI Plugin"}],"componentDesc":{"group":["01_04_03"]},"fileInfo":{"name":"Kubectl-ai","path":"operation/operate/Kubectl-ai.vue","directory":"operation/operate"}}},{"node":{"id":"1bc6e9edd49039c5b6582aff860d11fd","name":"Ai-ops-trouble-shooting","path":"/operation/operate/ai-ops-trouble-shooting/","props":[{"name":"Kubernetes Trouble shooting"}],"componentDesc":{"group":["01_04_04"]},"fileInfo":{"name":"Ai-ops-trouble-shooting","path":"operation/operate/Ai-ops-trouble-shooting.vue","directory":"operation/operate"}}},{"node":{"id":"ab9b4ae17d0be1d1ab1ffab705b40e6a","name":"AutoModeling","path":"/operation/planning/ai-auto-modeling/","props":[{"name":"AI-driven MSA 디자인"}],"componentDesc":{"group":["02_01_02"]},"fileInfo":{"name":"Ai-auto-modeling","path":"operation/planning/Ai-auto-modeling.vue","directory":"operation/planning"}}},{"node":{"id":"6d286e2e7109a1e4ca79e85d2160f019","name":"LLM-Model","path":"/llm/llm/llm-model/","props":[{"name":"Open Source LLM"}],"componentDesc":{"group":["05_01_02"]},"fileInfo":{"name":"LLM-model","path":"llm/llm/LLM-model.vue","directory":"llm/llm"}}},{"node":{"id":"2b1f504f43242783333fe6a589120ea1","name":"LLM-Setting","path":"/llm/llm/llm-setting/","props":[{"name":"설치형 LLM 개발 환경 구성"}],"componentDesc":{"group":["05_01_03"]},"fileInfo":{"name":"LLM-setting","path":"llm/llm/LLM-setting.vue","directory":"llm/llm"}}},{"node":{"id":"c6b8741db4919538e12c0d43ace8a123","name":"Ollama","path":"/llm/llm/ollama/","props":[{"name":"Ollama"}],"componentDesc":{"group":["05_01_04"]},"fileInfo":{"name":"ollama","path":"llm/llm/ollama.vue","directory":"llm/llm"}}},{"node":{"id":"59328fbc1fccb0281b638b1e7c807324","name":"Open-Web","path":"/llm/llm/open-web-ui/","props":[{"name":"Open Web UI"}],"componentDesc":{"group":["05_01_05"]},"fileInfo":{"name":"open-web-ui","path":"llm/llm/open-web-ui.vue","directory":"llm/llm"}}},{"node":{"id":"0d5fa973d42ab6a4abfc56a0b18e3789","name":"Overview","path":"/operation/llm-msaez/overview/","props":[{"name":"과정개요"}],"componentDesc":{"group":["06_01_02"]},"fileInfo":{"name":"Overview","path":"operation/llm-msaez/Overview.vue","directory":"operation/llm-msaez"}}}]},"allPages":{"edges":[{"node":{"name":"Ai-ops-trouble-shooting","path":"/operation/operate/ai-ops-trouble-shooting/","fileInfo":{"name":"Ai-ops-trouble-shooting","directory":"operation/operate"}}},{"node":{"name":"Kubectl-ai","path":"/operation/operate/kubectl-ai/","fileInfo":{"name":"Kubectl-ai","directory":"operation/operate"}}},{"node":{"name":"index","path":"/operation/operate/","fileInfo":{"name":"index","directory":"operation/operate"}}},{"node":{"name":"Fastfood","path":"/operation/operate/copilot-dockerising/","fileInfo":{"name":"Copilot-dockerising","directory":"operation/operate"}}},{"node":{"name":"SW","path":"/operation/introduction/sw/","fileInfo":{"name":"SW","directory":"operation/introduction"}}},{"node":{"name":"Legacy","path":"/operation/introduction/legacy/","fileInfo":{"name":"Legacy","directory":"operation/introduction"}}},{"node":{"name":"index","path":"/operation/introduction/","fileInfo":{"name":"index","directory":"operation/introduction"}}},{"node":{"name":"Kubernetes","path":"/operation/introduction/kubectl-ai/","fileInfo":{"name":"Kubectl-AI","directory":"operation/introduction"}}},{"node":{"name":"Continue","path":"/operation/introduction/continue/","fileInfo":{"name":"Continue","directory":"operation/introduction"}}},{"node":{"name":"IDE","path":"/operation/introduction/ide/","fileInfo":{"name":"IDE","directory":"operation/introduction"}}},{"node":{"name":"GPT-Engineer","path":"/operation/introduction/gpt-engineer/","fileInfo":{"name":"Gpt-engineer","directory":"operation/introduction"}}},{"node":{"name":"Overview","path":"/operation/llm-msaez/overview/","fileInfo":{"name":"Overview","directory":"operation/llm-msaez"}}},{"node":{"name":"index","path":"/operation/planning/","fileInfo":{"name":"index","directory":"operation/planning"}}},{"node":{"name":"Open-Web","path":"/llm/llm/open-web-ui/","fileInfo":{"name":"open-web-ui","directory":"llm/llm"}}},{"node":{"name":"Copilot-dev","path":"/operation/implement/copilot-dev/","fileInfo":{"name":"Copilot-dev","directory":"operation/implement"}}},{"node":{"name":"AutoModeling","path":"/operation/planning/ai-auto-modeling/","fileInfo":{"name":"Ai-auto-modeling","directory":"operation/planning"}}},{"node":{"name":"index","path":"/operation/llm-msaez/","fileInfo":{"name":"index","directory":"operation/llm-msaez"}}},{"node":{"name":"index","path":"/operation/implement/","fileInfo":{"name":"index","directory":"operation/implement"}}},{"node":{"name":"GPT-Engineer-dev","path":"/operation/implement/gpt-engineer-dev/","fileInfo":{"name":"GPT-Engineer-dev","directory":"operation/implement"}}},{"node":{"name":"index","path":"/operation/course/","fileInfo":{"name":"index","directory":"operation/course"}}},{"node":{"name":"LLM-Model","path":"/llm/llm/llm-model/","fileInfo":{"name":"LLM-model","directory":"llm/llm"}}},{"node":{"name":"LLM-Setting","path":"/llm/llm/llm-setting/","fileInfo":{"name":"LLM-setting","directory":"llm/llm"}}},{"node":{"name":"Ollama","path":"/llm/llm/ollama/","fileInfo":{"name":"ollama","directory":"llm/llm"}}},{"node":{"name":"index","path":"/llm/llm/","fileInfo":{"name":"index","directory":"llm/llm"}}}]}},"context":{"pathRegexp":"^$path.+$"}}