{"hash":"285a57cf25d0c1f147645b0a93803bde1838ba88","data":{"thisPage":{"id":"480ae649e5360217a72b11cabcefb6dc","name":"Ollama","mockData":"{\"Ollama\":\"back up\"}","source":"<template>\n    <div>\n        <mark-down class=\"content\">\n            \n## Ollama\n\nOllama는 로컬 LLM을 구축할 수 있는 솔루션으로, 모든 운영체제에서 사용 가능합니다(Windows는 베타 버전 지원).\n\n**https://ollama.com/** 에서 운영체제 선택 후 다운로드 가능합니다. \n\n![4 56 35](https://github.com/msa-ez/llmschool.github.io/assets/113568664/fc28b209-97a6-40c8-a6b4-b3be0ca231cd)\n\n**https://ollama.com/library** 에서는 Ollama에서 제공하는 전체 모델 리스트를 확인할 수 있는데, gemma, llama2, mistral 등 인기 있는 모델은 대부분 제공하고 있습니다. \n\n![4 59 15](https://github.com/msa-ez/llmschool.github.io/assets/113568664/72ef2188-a2c0-461a-b786-794d40c1bbf5)\n\n특정 모델을 선택하면 해당 모델의 정보를 확인할 수 있는데, Tag를 확인해 모델의 구체적인 정보를 선택해 사용할 수 있습니다. **latest** 버전을 선택하면 가장 최신 버전을 적용할 수 있습니다. \n\n![5 07 38](https://github.com/msa-ez/llmschool.github.io/assets/113568664/e3115dd8-f12f-4d4c-8313-0874c92616ab)\n\n### Ollama Model Tag\n\n|  기본 태그 | 용도 | 파라미터 | 양자화 |\n| ---|---|---|---|\n| latest : 최신모델 | instruct : 채팅 전용으로 Fine-tuning 한 모델(Default)  | 7b : 7 Billions 모델  | q2, q3, q4, q5, q6, q7, q8 : X Bit로 양자화(높은 비트로 양자화 한 것일수록 손실 적음)  |\n|  vX : 모델의 버전 | text : 텍스트 완성 전용, 초기모델  | 13b : 13 Billions 모델  | K, K_S, K_M, K_L : 변형 방법(일반적으로 성능은 S - M - L 순서대로 좋음)  |\n\nOllama는 채팅 모델을 기본으로 삼아 주로 instruct 모델을 latest로 설정합니다.\n\n또한 모델에서 사용하는 실제 파라미터는 디테일 높은 수준의 값을 웨이트로 사용하기 때문에 용량이 너무 크다는 문제점이 있는데, 이를 해결하기 위해 양자화를 통해 정밀도를 낮추고 용량을 아끼는 방법을 채택했습니다. \n\n굉장히 큰 소수(0.xxxxxxx...)로 구성된 파라미터를 반올림하는 것인데, 반올림을 얼마나 많이 했는지에 따라 q8부터 q2까지 다양합니다. \n\nq8은 원본과 거의 비슷한 수준의 정밀도를 보여주지만 용량 면에서도 큰 차이를 보이지 않습니다. q2 수준으로 내려가게 되면 양자화의 반올림 정도가 심해 모델의 정확도가 떨어지게 됩니다.\n\n어느 정도의 성능도 보장이 되면서 용량 절약까지 가져가기 위해서는 q4~5 정도가 적당하고, Ollama에서도 이 정도 수준을 기본 양자화 모델로 채택합니다. \n\n![스크린샷 2024-03-05 오후 3 17 37](https://github.com/msa-ez/llmschool.github.io/assets/113568664/1ffbc893-2212-4d56-8768-73a828b8a7f3)\n\n하나의 예로 실제 Ollama에서 Mistral 모델의 태그 중 일부를 보면 **7b-instruct-q5_K_S** 와 같은 형태로 나타나는데, 이를 해석하면 7b 파라미터를 가진 instruct 모델을 q5 수준으로 양자화한 버전이라고 해석할 수 있습니다. \n\n### Ollama 기본 명령어\n\n- **Serve** : 서버 시작 - Ollama를 실행하면 기본적으로 서버가 올라가므로 별도 입력할 필요 X\n- **Pull** : 모델을 받아서 로컬에 저장\n- **List** : 저장된 모델 조회\n- **Run** : 선택한 모델로 콘솔 테스트 - 앞서 Pull 받지 않아도 Run 명령어 실행 시 자동으로 Pull을 진행\n- **Rm** : 선택한 모델 삭제\n- **Create** : Modelfile로부터 모델 추가 - Ollama에 새로운 커스텀 모델을 등록할 때 사용\n\n위 명령어로 Ollama에서 Mistral 모델을 활용하는 방법을 예로 들면 다음과 같습니다. \n```\nollama pull mistral //mistral 모델 로컬에 저장\n```\n```\nollama list //설치된 모델 확인\n```\n```\nollama run mistral //설치된 모델 테스트\n```\n        </mark-down>\n\n    </div>\n</template>\n\n\n<script>\n    // @group 05_01_04\n    export default {\n        name:'Ollama',\n        data() {\n            return {}\n        },\n        props: {\n            \"Ollama\": {\n                type: String\n            },\n        },\n    }\n</script>","path":"/llm/llm/ollama/","props":[{"name":"Ollama"}],"componentDesc":{"group":["05_01_04"]},"fileInfo":{"name":"ollama","path":"llm/llm/ollama.vue","directory":"llm/llm"}},"allPagesByName":{"edges":[{"node":{"id":"521ea353b5b2ec2c3e0f9f5be3a13039","name":"index","path":"/llm/llm/","props":[{"name":"설치형 LLM"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"llm/llm/index.vue","directory":"llm/llm"}}},{"node":{"id":"491a019883e24d1ade45318efd39fa7e","name":"index","path":"/operation/course/","props":[{"name":"교육과정 소개"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/course/index.vue","directory":"operation/course"}}},{"node":{"id":"455485b89fc07a2011135c71b3e5b06d","name":"index","path":"/operation/introduction/","props":[{"name":"AI 코딩 도구"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/introduction/index.vue","directory":"operation/introduction"}}},{"node":{"id":"ddac7512ff1cb42577161679388846a0","name":"index","path":"/operation/implement/","props":[{"name":"구현"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/implement/index.vue","directory":"operation/implement"}}},{"node":{"id":"dfe15286a0af9af4cf957c89714797f4","name":"index","path":"/operation/llm-msaez/","props":[{"name":"Overview"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/llm-msaez/index.vue","directory":"operation/llm-msaez"}}},{"node":{"id":"0bb6a8c5fa0e1266e2ccecc243fa5470","name":"index","path":"/operation/operate/","props":[{"name":"배포/운영"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/operate/index.vue","directory":"operation/operate"}}},{"node":{"id":"eeaab9630dc4711635747aa9fda862d7","name":"index","path":"/operation/planning/","props":[{"name":"분석/설계"}],"componentDesc":{"group":[]},"fileInfo":{"name":"index","path":"operation/planning/index.vue","directory":"operation/planning"}}},{"node":{"id":"ca5edeb926047bc16e52379ccb4cdbd6","name":"IDE","path":"/operation/introduction/ide/","props":[{"name":"Cursor IDE"}],"componentDesc":{"group":["01_01_02"]},"fileInfo":{"name":"IDE","path":"operation/introduction/IDE.vue","directory":"operation/introduction"}}},{"node":{"id":"b226ba8089a5b8e4cc79a46bdf60d587","name":"SW","path":"/operation/introduction/sw/","props":[{"name":"테스트생성과 리팩토링"}],"componentDesc":{"group":["01_01_03"]},"fileInfo":{"name":"SW","path":"operation/introduction/SW.vue","directory":"operation/introduction"}}},{"node":{"id":"ef65af528625f3df4341f189681a2066","name":"Legacy","path":"/operation/introduction/legacy/","props":[{"name":"레거시분석과 모더나이징"}],"componentDesc":{"group":["01_01_04"]},"fileInfo":{"name":"Legacy","path":"operation/introduction/Legacy.vue","directory":"operation/introduction"}}},{"node":{"id":"d894f03fb84bd2357e5f6115f61b2cd9","name":"GPT-Engineer","path":"/operation/introduction/gpt-engineer/","props":[{"name":"GPT-Engineer"}],"componentDesc":{"group":["01_01_05"]},"fileInfo":{"name":"Gpt-engineer","path":"operation/introduction/Gpt-engineer.vue","directory":"operation/introduction"}}},{"node":{"id":"7e9f91dcd66fc903b29ed35c1bdb3953","name":"Continue","path":"/operation/introduction/continue/","props":[{"name":"Continue 코파일럿"}],"componentDesc":{"group":["01_01_06"]},"fileInfo":{"name":"Continue","path":"operation/introduction/Continue.vue","directory":"operation/introduction"}}},{"node":{"id":"8436578d14e4c980d7c1ee8fa899962a","name":"Kubernetes","path":"/operation/introduction/kubectl-ai/","props":[{"name":"쿠버네티스 AI 플러그인"}],"componentDesc":{"group":["01_01_07"]},"fileInfo":{"name":"Kubectl-AI","path":"operation/introduction/Kubectl-AI.vue","directory":"operation/introduction"}}},{"node":{"id":"3bd2f88491ffe8e5d3e0cb8f5ad49c5e","name":"GPT-Engineer-dev","path":"/operation/implement/gpt-engineer-dev/","props":[{"name":"MSA Chassis by Autopilot"}],"componentDesc":{"group":["01_03_02"]},"fileInfo":{"name":"GPT-Engineer-dev","path":"operation/implement/GPT-Engineer-dev.vue","directory":"operation/implement"}}},{"node":{"id":"bec8e6134b4833a31df0a230c20b0464","name":"Copilot-dev","path":"/operation/implement/copilot-dev/","props":[{"name":"Business Logic by Copilot"}],"componentDesc":{"group":["01_03_03"]},"fileInfo":{"name":"Copilot-dev","path":"operation/implement/Copilot-dev.vue","directory":"operation/implement"}}},{"node":{"id":"c6aafe599a891c74b0fb229795490cdd","name":"Fastfood","path":"/operation/operate/copilot-dockerising/","props":[{"name":"Github Action 활용"}],"componentDesc":{"group":["01_04_02"]},"fileInfo":{"name":"Copilot-dockerising","path":"operation/operate/Copilot-dockerising.vue","directory":"operation/operate"}}},{"node":{"id":"ac0be07f9c57dce30509a7d323a406e6","name":"Kubectl-ai","path":"/operation/operate/kubectl-ai/","props":[{"name":"Kubectl OpenAI Plugin"}],"componentDesc":{"group":["01_04_03"]},"fileInfo":{"name":"Kubectl-ai","path":"operation/operate/Kubectl-ai.vue","directory":"operation/operate"}}},{"node":{"id":"f3d7168080d3c0d2ee96cd83a9434c8c","name":"Ai-ops-trouble-shooting","path":"/operation/operate/ai-ops-trouble-shooting/","props":[{"name":"Kubernetes Trouble shooting"}],"componentDesc":{"group":["01_04_04"]},"fileInfo":{"name":"Ai-ops-trouble-shooting","path":"operation/operate/Ai-ops-trouble-shooting.vue","directory":"operation/operate"}}},{"node":{"id":"8de86484c2e4943142d33cb5568bad99","name":"AutoModeling","path":"/operation/planning/ai-auto-modeling/","props":[{"name":"AI-driven MSA 디자인"}],"componentDesc":{"group":["02_01_02"]},"fileInfo":{"name":"Ai-auto-modeling","path":"operation/planning/Ai-auto-modeling.vue","directory":"operation/planning"}}},{"node":{"id":"f20ca5519dcdfdfd2a9b75f166de4303","name":"LLM-Model","path":"/llm/llm/llm-model/","props":[{"name":"Open Source LLM"}],"componentDesc":{"group":["05_01_02"]},"fileInfo":{"name":"LLM-model","path":"llm/llm/LLM-model.vue","directory":"llm/llm"}}},{"node":{"id":"32fb961852082ac931ed4dfc51178da6","name":"LLM-Setting","path":"/llm/llm/llm-setting/","props":[{"name":"설치형 LLM 개발 환경 구성"}],"componentDesc":{"group":["05_01_03"]},"fileInfo":{"name":"LLM-setting","path":"llm/llm/LLM-setting.vue","directory":"llm/llm"}}},{"node":{"id":"480ae649e5360217a72b11cabcefb6dc","name":"Ollama","path":"/llm/llm/ollama/","props":[{"name":"Ollama"}],"componentDesc":{"group":["05_01_04"]},"fileInfo":{"name":"ollama","path":"llm/llm/ollama.vue","directory":"llm/llm"}}},{"node":{"id":"52c918cf6bf34c4bdf3b4235e65147d4","name":"Open-Web","path":"/llm/llm/open-web-ui/","props":[{"name":"Open Web UI"}],"componentDesc":{"group":["05_01_05"]},"fileInfo":{"name":"open-web-ui","path":"llm/llm/open-web-ui.vue","directory":"llm/llm"}}},{"node":{"id":"388fff31369b007c6efc46b2e289576e","name":"Overview","path":"/operation/llm-msaez/overview/","props":[{"name":"과정개요"}],"componentDesc":{"group":["06_01_02"]},"fileInfo":{"name":"Overview","path":"operation/llm-msaez/Overview.vue","directory":"operation/llm-msaez"}}}]},"allPages":{"edges":[{"node":{"name":"index","path":"/operation/planning/","fileInfo":{"name":"index","directory":"operation/planning"}}},{"node":{"name":"AutoModeling","path":"/operation/planning/ai-auto-modeling/","fileInfo":{"name":"Ai-auto-modeling","directory":"operation/planning"}}},{"node":{"name":"index","path":"/operation/operate/","fileInfo":{"name":"index","directory":"operation/operate"}}},{"node":{"name":"Kubectl-ai","path":"/operation/operate/kubectl-ai/","fileInfo":{"name":"Kubectl-ai","directory":"operation/operate"}}},{"node":{"name":"Fastfood","path":"/operation/operate/copilot-dockerising/","fileInfo":{"name":"Copilot-dockerising","directory":"operation/operate"}}},{"node":{"name":"Ai-ops-trouble-shooting","path":"/operation/operate/ai-ops-trouble-shooting/","fileInfo":{"name":"Ai-ops-trouble-shooting","directory":"operation/operate"}}},{"node":{"name":"index","path":"/operation/llm-msaez/","fileInfo":{"name":"index","directory":"operation/llm-msaez"}}},{"node":{"name":"GPT-Engineer-dev","path":"/operation/implement/gpt-engineer-dev/","fileInfo":{"name":"GPT-Engineer-dev","directory":"operation/implement"}}},{"node":{"name":"Overview","path":"/operation/llm-msaez/overview/","fileInfo":{"name":"Overview","directory":"operation/llm-msaez"}}},{"node":{"name":"index","path":"/operation/implement/","fileInfo":{"name":"index","directory":"operation/implement"}}},{"node":{"name":"Copilot-dev","path":"/operation/implement/copilot-dev/","fileInfo":{"name":"Copilot-dev","directory":"operation/implement"}}},{"node":{"name":"index","path":"/operation/introduction/","fileInfo":{"name":"index","directory":"operation/introduction"}}},{"node":{"name":"SW","path":"/operation/introduction/sw/","fileInfo":{"name":"SW","directory":"operation/introduction"}}},{"node":{"name":"Legacy","path":"/operation/introduction/legacy/","fileInfo":{"name":"Legacy","directory":"operation/introduction"}}},{"node":{"name":"Kubernetes","path":"/operation/introduction/kubectl-ai/","fileInfo":{"name":"Kubectl-AI","directory":"operation/introduction"}}},{"node":{"name":"IDE","path":"/operation/introduction/ide/","fileInfo":{"name":"IDE","directory":"operation/introduction"}}},{"node":{"name":"Continue","path":"/operation/introduction/continue/","fileInfo":{"name":"Continue","directory":"operation/introduction"}}},{"node":{"name":"index","path":"/operation/course/","fileInfo":{"name":"index","directory":"operation/course"}}},{"node":{"name":"GPT-Engineer","path":"/operation/introduction/gpt-engineer/","fileInfo":{"name":"Gpt-engineer","directory":"operation/introduction"}}},{"node":{"name":"Open-Web","path":"/llm/llm/open-web-ui/","fileInfo":{"name":"open-web-ui","directory":"llm/llm"}}},{"node":{"name":"Ollama","path":"/llm/llm/ollama/","fileInfo":{"name":"ollama","directory":"llm/llm"}}},{"node":{"name":"index","path":"/llm/llm/","fileInfo":{"name":"index","directory":"llm/llm"}}},{"node":{"name":"LLM-Setting","path":"/llm/llm/llm-setting/","fileInfo":{"name":"LLM-setting","directory":"llm/llm"}}},{"node":{"name":"LLM-Model","path":"/llm/llm/llm-model/","fileInfo":{"name":"LLM-model","directory":"llm/llm"}}}]}},"context":{"pathRegexp":"^$path.+$"}}